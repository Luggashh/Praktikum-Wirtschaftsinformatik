{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15ec7a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"pip\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "! pip install haystack-ai haystack-integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9ab78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from haystack import Pipeline, Document, component\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.retrievers import InMemoryBM25Retriever\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore \n",
    "from haystack.dataclasses import ChatMessage\n",
    "# Import OllamaChatGenerator - muss separat installiert werden\n",
    "from haystack_integrations.components.generators.ollama import OllamaChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e16d1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a \n",
    "\n",
    "\n",
    "bpmn_examples = [\n",
    "    {\"bpmn\": '<bpmn:startEvent id=\"StartEvent_1\"/><bpmn:task id=\"T1\" name=\"Check Credit\"/><bpmn:task id=\"T2\" name=\"Approve Loan\"/>', \n",
    "     \"text\": \"The process starts with checking the customer's credit score. If the score is sufficient, the task is to approve the loan.\"},\n",
    "    {\"bpmn\": '<bpmn:startEvent id=\"Start\"/><bpmn:task id=\"T3\" name=\"Process Order\"/><bpmn:task id=\"T4\" name=\"Ship Product\"/><bpmn:endEvent id=\"End\"/>', \n",
    "     \"text\": \"First, process the received order. Once processing is complete, ship the final product to the customer.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd508694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "documents = [\n",
    "    Document(content=ex[\"bpmn\"], meta={\"text\": ex[\"text\"], \"id\": f\"doc_{i}\"})\n",
    "    for i, ex in enumerate(bpmn_examples)\n",
    "]\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a10e373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = [\n",
    "    ChatMessage.from_system(\"\"\"\n",
    "You are an expert BPMN text generator. Your task is to analyze the user-provided \n",
    "BPMN XML fragments and create a clear, natural language description of the process.\n",
    "\n",
    "CRITICAL RULE: The tasks in your description MUST be enclosed in <bpmn:task>Task Name</bpmn:task> tags.\n",
    "Example Tag Usage: <bpmn:task>Task Name</bpmn:task>\n",
    "    \"\"\"),\n",
    "    ChatMessage.from_user(\"\"\"\n",
    "--- Example Context (Retrieved from Document Store) ---\n",
    "BPMN Example XML: {{examples.0.content}}\n",
    "Text Example: {{examples.0.meta.text}}\n",
    "------------------------------------------------------\n",
    "\n",
    "Now, create a textual description for the following BPMN XML fragment:\n",
    "{{query_bpmn}}\n",
    "\n",
    "Remember to use the <bpmn:task>Task Name</bpmn:task> tags for every task name.\n",
    "    \"\"\")\n",
    "]\n",
    "prompt_builder = ChatPromptBuilder(template=prompt_template, required_variables=[\"query_bpmn\", \"examples\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745beb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2c. Matching Generator: LLM to perform the generation.\n",
    "# NOTE: Replace the model and URL if necessary.\n",
    "chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30*60,\n",
    "    generation_kwargs={\"temperature\": 0.3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db6ae25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x00000134988C8B90>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - generator: OllamaChatGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.examples (list[Document])\n",
       "  - prompt_builder.prompt -> generator.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline, that recieves all comoponents\n",
    "bpmn_pipeline = Pipeline()\n",
    "\n",
    "# Add components\n",
    "bpmn_pipeline.add_component(instance=retriever, name=\"retriever\")\n",
    "bpmn_pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "bpmn_pipeline.add_component(instance=chat_generator, name=\"generator\")\n",
    "\n",
    "# Connect components\n",
    "# 1. Provide the query (the new BPMN model) to the Retriever\n",
    "bpmn_pipeline.connect(\"retriever.documents\", \"prompt_builder.examples\") \n",
    "# 2. Pass the retrieved documents (as 'examples') to the PromptBuilder\n",
    "bpmn_pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51d7da87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated annotated text:\n",
      "The process begins with a start event. Next, log the customer's complaint in detail. After that, investigate the issue thoroughly. Finally, process the refund request.\n"
     ]
    }
   ],
   "source": [
    "# Test BPMN model with matching generator 3a 2.\n",
    "test_bpmn = \"\"\"<bpmn:startEvent id=\"Start\"/>\n",
    "<bpmn:task id=\"T1\" name=\"Log Complaint\"/>\n",
    "<bpmn:task id=\"T2\" name=\"Investigate Issue\"/>\n",
    "<bpmn:task id=\"T3\" name=\"Process Refund\"/>\"\"\"\n",
    "\n",
    "# Run pipeline\n",
    "result = bpmn_pipeline.run({\n",
    "    \"retriever\": {\"query\": test_bpmn, \"top_k\": 1},\n",
    "    \"prompt_builder\": {\"query_bpmn\": test_bpmn}\n",
    "})\n",
    "\n",
    "print(\"Generated annotated text:\")\n",
    "print(result[\"generator\"][\"replies\"][0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c445980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXERCISE 3b) PIPELINE EXECUTION & EVALUATION ===\n",
      "\n",
      "============================================================\n",
      "Model 1: Customer Onboarding (5 Tasks)\n",
      "============================================================\n",
      "âœ— Pipeline failed: Component named promptbuilder not found in the pipeline.\n",
      "\n",
      "ðŸ“Š EVALUATION RESULTS:\n",
      "  Ground Truth (5 tasks): ['Verify Identity', 'Perform KYC Check', 'Set up Account', 'Approve Application', 'Fund Account']\n",
      "  Extracted Tasks (0): []\n",
      "  Precision: 0.0000 | Recall: 0.0000\n",
      "  TP: 0 | FP: 0 | FN: 5\n",
      "\n",
      "============================================================\n",
      "Model 2: Complaint Resolution (6 Tasks)\n",
      "============================================================\n",
      "âœ— Pipeline failed: Component named promptbuilder not found in the pipeline.\n",
      "\n",
      "ðŸ“Š EVALUATION RESULTS:\n",
      "  Ground Truth (6 tasks): ['Log Complaint', 'Investigate Issue', 'Process Refund', 'Notify Finance', 'Send Resolution Email', 'Update CRM']\n",
      "  Extracted Tasks (0): []\n",
      "  Precision: 0.0000 | Recall: 0.0000\n",
      "  TP: 0 | FP: 0 | FN: 6\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ˆ PRESENTATION TABLE - Exercise 3b Results\n",
      "================================================================================\n",
      "                         Model  Precision  Recall  TP  FP  FN  GT_Total\n",
      " Customer Onboarding (5 Tasks)        0.0     0.0   0   0   5         5\n",
      "Complaint Resolution (6 Tasks)        0.0     0.0   0   0   6         6\n",
      "\n",
      "âœ… Ready for presentation!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "# 1. Define 2 test BPMN models with ground truth (Exercise 3b requirement)\n",
    "TEST_BPMN_MODELS = [\n",
    "    {\n",
    "        \"name\": \"Customer Onboarding (5 Tasks)\",\n",
    "        \"xml\": \"\"\"<bpmn:startEvent id=\"Start\"/>\n",
    "<bpmn:task id=\"T1\" name=\"Verify Identity\"/>\n",
    "<bpmn:task id=\"T2\" name=\"Perform KYC Check\"/>\n",
    "<bpmn:task id=\"T3\" name=\"Set up Account\"/>\n",
    "<bpmn:task id=\"T4\" name=\"Approve Application\"/>\n",
    "<bpmn:task id=\"T5\" name=\"Fund Account\"/>\"\"\",\n",
    "        \"ground_truth\": [\"Verify Identity\", \"Perform KYC Check\", \"Set up Account\", \"Approve Application\", \"Fund Account\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Complaint Resolution (6 Tasks)\",\n",
    "        \"xml\": \"\"\"<bpmn:startEvent id=\"Start\"/>\n",
    "<bpmn:task id=\"T1\" name=\"Log Complaint\"/>\n",
    "<bpmn:task id=\"T2\" name=\"Investigate Issue\"/>\n",
    "<bpmn:task id=\"T3\" name=\"Process Refund\"/>\n",
    "<bpmn:task id=\"T4\" name=\"Notify Finance\"/>\n",
    "<bpmn:task id=\"T5\" name=\"Send Resolution Email\"/>\n",
    "<bpmn:task id=\"T6\" name=\"Update CRM\"/>\"\"\",\n",
    "        \"ground_truth\": [\"Log Complaint\", \"Investigate Issue\", \"Process Refund\", \"Notify Finance\", \"Send Resolution Email\", \"Update CRM\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. Task extraction from annotated LLM output\n",
    "def extract_and_clean_tasks(text: str) -> List[str]:\n",
    "    \"\"\"Extract task names from <bpmn:task> tags - FIXED REGEX\"\"\"\n",
    "    tasks = re.findall(r'<bpmn:task[^>]*name=\"([^\"]*)\"[^>]*>', text, re.IGNORECASE)\n",
    "    return [task.strip() for task in tasks if task.strip()]\n",
    "\n",
    "# 3. Precision/Recall calculation (standard IR metrics for BPMN task extraction)\n",
    "def calculate_precision_recall(predicted: List[str], ground_truth: List[str]) -> Dict:\n",
    "    pred_set = {t.lower() for t in predicted if t}\n",
    "    gt_set = {t.lower() for t in ground_truth}\n",
    "    \n",
    "    tp = len(pred_set & gt_set)\n",
    "    fp = len(pred_set - gt_set)\n",
    "    fn = len(gt_set - pred_set)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn,\n",
    "        \"GT_Total\": len(ground_truth)\n",
    "    }\n",
    "\n",
    "# 4. Run pipeline for 2 models + evaluate\n",
    "print(\"=== EXERCISE 3b) PIPELINE EXECUTION & EVALUATION ===\\n\")\n",
    "results_summary = []\n",
    "\n",
    "for i, model in enumerate(TEST_BPMN_MODELS, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Model {i}: {model['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Run the pipeline (assumes bpmn_annotation_pipeline from 3a exists)\n",
    "    try:\n",
    "        result = bpmn_pipeline.run({\n",
    "            \"retriever\": {\"query\": model[\"xml\"], \"top_k\": 1},\n",
    "            \"promptbuilder\": {\"query_bpmn\": model[\"xml\"]}\n",
    "        })\n",
    "        \n",
    "        llm_output = result[\"generator\"][\"replies\"][0].text\n",
    "        predicted_tasks = extract_bpmn_tasks(llm_output)\n",
    "        \n",
    "        print(\"âœ“ Pipeline executed successfully\")\n",
    "        print(\"LLM Output preview:\", llm_output[:300] + \"...\" if len(llm_output) > 300 else llm_output)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Pipeline failed: {e}\")\n",
    "        predicted_tasks = []\n",
    "        llm_output = \"ERROR\"\n",
    "    \n",
    "    # Calculate scores\n",
    "    scores = calculate_precision_recall(predicted_tasks, model[\"ground_truth\"])\n",
    "    \n",
    "    # Store for presentation\n",
    "    results_summary.append({\n",
    "        \"Model\": model[\"name\"],\n",
    "        \"GroundTruth\": model[\"ground_truth\"],\n",
    "        \"PredictedTasks\": predicted_tasks,\n",
    "        \"LLM_Output\": llm_output,\n",
    "        \"Scores\": scores\n",
    "    })\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\nðŸ“Š EVALUATION RESULTS:\")\n",
    "    print(f\"  Ground Truth ({len(model['ground_truth'])} tasks): {model['ground_truth']}\")\n",
    "    print(f\"  Extracted Tasks ({len(predicted_tasks)}): {predicted_tasks}\")\n",
    "    print(f\"  Precision: {scores['Precision']:.4f} | Recall: {scores['Recall']:.4f}\")\n",
    "    print(f\"  TP: {scores['TP']} | FP: {scores['FP']} | FN: {scores['FN']}\")\n",
    "    print()\n",
    "\n",
    "# 5. Presentation-ready table (copy to slides)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“ˆ PRESENTATION TABLE - Exercise 3b Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scores_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": r[\"Model\"],\n",
    "        \"Precision\": r[\"Scores\"][\"Precision\"],\n",
    "        \"Recall\": r[\"Scores\"][\"Recall\"],\n",
    "        \"TP\": r[\"Scores\"][\"TP\"],\n",
    "        \"FP\": r[\"Scores\"][\"FP\"], \n",
    "        \"FN\": r[\"Scores\"][\"FN\"],\n",
    "        \"GT_Total\": r[\"Scores\"][\"GT_Total\"]\n",
    "    }\n",
    "    for r in results_summary\n",
    "])\n",
    "\n",
    "print(scores_df.to_string(index=False))\n",
    "print(\"\\nâœ… Ready for presentation!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
