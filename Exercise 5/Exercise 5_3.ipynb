{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773a0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPMN MODEL                | TYPE         | SCORE | SAMPLE TEXT (Truncated)\n",
      "------------------------------------------------------------------------------------------\n",
      "Error extracting score: Expecting value: line 1 column 1 (char 0)\n",
      "1. Delayed Baggage        | Human        | 9     | The process regarding delayed baggage be...\n",
      "                          | Generated    | 0     | Start event passenger notices missing it...\n",
      "------------------------------------------------------------------------------------------\n",
      "Error extracting score: Expecting value: line 1 column 1 (char 0)\n",
      "Error extracting score: Expecting value: line 1 column 1 (char 0)\n",
      "2. Security Check         | Human        | 0     | The process is initiated when the passen...\n",
      "                          | Generated    | 0     | Start event show boarding pass. Task exe...\n",
      "------------------------------------------------------------------------------------------\n",
      "Error extracting score: Expecting value: line 1 column 1 (char 0)\n",
      "Error extracting score: Expecting value: line 1 column 1 (char 0)\n",
      "3. Arrivals & Customs     | Human        | 0     | The process begins when the passenger ar...\n",
      "                          | Generated    | 0     | Passenger arrives start event. Exclusive...\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from haystack import Pipeline\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack_integrations.components.generators.ollama import OllamaChatGenerator\n",
    "\n",
    "# ==========================================\n",
    "# 1. READABILITY SCORING COMPONENT\n",
    "# ==========================================\n",
    "class ReadabilityScorer:\n",
    "    def __init__(self):\n",
    "        # A. Define the Prompt Template\n",
    "        # We ask the LLM to score clarity/flow on a scale of 0-10\n",
    "        template_text = \"\"\"\n",
    "        You are an expert linguist and technical evaluator.\n",
    "        Analyze the following text describing a Business Process (BPMN).\n",
    "\n",
    "        Criteria for scoring:\n",
    "        - **10**: Natural, flowing, easy to read, human-like structure.\n",
    "        - **5**: Understandable but robotic, repetitive, or fragmented.\n",
    "        - **0**: Unintelligible or unstructured.\n",
    "\n",
    "        Text to Evaluate:\n",
    "        \"{{ passage }}\"\n",
    "\n",
    "        Return your evaluation strictly as a JSON object with a single key \"score\" (integer 0-10).\n",
    "        Example: {\"score\": 8}\n",
    "        \"\"\"\n",
    "\n",
    "        # B. Initialize Components\n",
    "        prompt_builder = ChatPromptBuilder(\n",
    "            template=[ChatMessage.from_user(template_text)],\n",
    "            required_variables=[\"passage\"]\n",
    "        )\n",
    "\n",
    "        # Using Llama 3.1:8b (ensure it is pulled via 'ollama pull llama3.1:8b')\n",
    "        llm = OllamaChatGenerator(\n",
    "            model=\"llama3.1:8b\", \n",
    "            url=\"http://localhost:11434\",\n",
    "            generation_kwargs={\n",
    "                \"format\": \"json\", # Enforces valid JSON output\n",
    "                \"temperature\": 0.0 # Deterministic output for scoring\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # C. Build the Pipeline\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "        self.pipeline.add_component(\"llm\", llm)\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "\n",
    "    def get_score(self, text):\n",
    "        try:\n",
    "            result = self.pipeline.run({\"prompt_builder\": {\"passage\": text}})\n",
    "            response_text = result[\"llm\"][\"replies\"][0].text\n",
    "            data = json.loads(response_text)\n",
    "            return int(data.get(\"score\", 0))\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting score: {e}\")\n",
    "            return 0\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA SETUP (3 Models)\n",
    "# ==========================================\n",
    "# We compare the texts you provided (Human) against simulated \"Generated\" output.\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"model_name\": \"1. Delayed Baggage\",\n",
    "        # YOUR TEXT (Ground Truth)\n",
    "        \"human_text\": (\n",
    "            \"The process regarding delayed baggage begins when a passenger notices their item is missing upon arrival at the destination. \"\n",
    "            \"The passenger immediately reports the delayed baggage, either online or at the airport's baggage tracing counter. \"\n",
    "            \"Parallel to the main process, the passenger has the option to check the status of their report online at any time. \"\n",
    "            \"Once the report is filed, the airline or baggage service initiates the tracing procedure. As soon as the baggage is located, \"\n",
    "            \"it is forwarded to the destination airport, where it undergoes customs clearance and internal processing.\"\n",
    "        ),\n",
    "        # SIMULATED GENERATED TEXT (Robotic/Bad)\n",
    "        \"generated_text\": (\n",
    "            \"Start event passenger notices missing item. Task passenger reports delayed baggage. \"\n",
    "            \"Parallel gateway split. Sequence flow 1 check status online. Sequence flow 2 initiate tracing. \"\n",
    "            \"Task locate baggage. Task forward to destination. Task customs clearance. End event.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"2. Security Check\",\n",
    "        # YOUR TEXT (Ground Truth)\n",
    "        \"human_text\": (\n",
    "            \"The process is initiated when the passenger shows their boarding pass. Afterwards, the passenger proceeds to the security check area to undergo a security check. \"\n",
    "            \"Following the screening, a decision is made regarding whether the passenger appears suspicious. \"\n",
    "            \"If the passenger is deemed suspicious, they must undergo a manual control; if not, the manual control is skipped. \"\n",
    "            \"Subsequently, the process evaluates the passenger's destination via a gateway checking if the target destination is within the Schengen Area.\"\n",
    "        ),\n",
    "        # SIMULATED GENERATED TEXT (Robotic/Bad)\n",
    "        \"generated_text\": (\n",
    "            \"Start event show boarding pass. Task execute security check. Exclusive gateway suspicious? \"\n",
    "            \"If yes, execute manual control. If no, proceed. Exclusive gateway Schengen area? \"\n",
    "            \"If yes, skip passport control. If no, show passport. End process.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"3. Arrivals & Customs\",\n",
    "        # YOUR TEXT (Ground Truth)\n",
    "        \"human_text\": (\n",
    "            \"The process begins when the passenger arrives at the terminal. The flow immediately reaches an exclusive gateway that checks if the arrival is from the Schengen area. \"\n",
    "            \"If the arrival is from the Schengen area, the passenger proceeds to passport control and shows their passport. \"\n",
    "            \"If the arrival is not from the Schengen area, these control steps are skipped. \"\n",
    "            \"Subsequently, the passenger goes to the baggage claim area.\"\n",
    "        ),\n",
    "        # SIMULATED GENERATED TEXT (Robotic/Bad)\n",
    "        \"generated_text\": (\n",
    "            \"Passenger arrives start event. Exclusive Gateway Schengen check. Sequence flow yes passport control. \"\n",
    "            \"Sequence flow no skip. Task baggage claim. Gateway has baggage? Yes take baggage. \"\n",
    "            \"No proceed. Gateway declare goods? Task declare goods. End event.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 3. RUN EXPERIMENT\n",
    "# ==========================================\n",
    "scorer = ReadabilityScorer()\n",
    "\n",
    "print(f\"{'BPMN MODEL':<25} | {'TYPE':<12} | {'SCORE':<5} | {'SAMPLE TEXT (Truncated)'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for exp in experiments:\n",
    "    # 1. Evaluate Human Text\n",
    "    human_score = scorer.get_score(exp[\"human_text\"])\n",
    "    \n",
    "    # 2. Evaluate Generated Text\n",
    "    gen_score = scorer.get_score(exp[\"generated_text\"])\n",
    "    \n",
    "    # 3. Print Results\n",
    "    print(f\"{exp['model_name']:<25} | {'Human':<12} | {human_score:<5} | {exp['human_text'][:40]}...\")\n",
    "    print(f\"{'':<25} | {'Generated':<12} | {gen_score:<5} | {exp['generated_text'][:40]}...\")\n",
    "    print(\"-\" * 90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
